{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktFg2jj3jTE6"
   },
   "source": [
    "# ACTIVIDAD 3: Deep Learning para Clasificación de Texto\n",
    "\n",
    "Edison Giraldo<br>\n",
    "Joel Orellana<br>\n",
    "Ruben Aponte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZ-OuW5DiLJs"
   },
   "source": [
    "En esta actividad vamos a trabajar en clasificar textos. Se recorrerá todo el proceso desde traer el dataset hasta proceder a dicha clasificación. Durante la actividad se llevarán a cabo muchos procesos como la creación de un vocabulario, el uso de embeddings y la creación de modelos.\n",
    "\n",
    "Las cuestiones presentes en esta actividad están basadas en un Notebook creado por François Chollet, uno de los creadores de Keras y autor del libro \"Deep Learning with Python\". \n",
    "\n",
    "En este Notebook se trabaja con el dataset \"Newsgroup20\" que contiene aproximadamente 20000 mensajes que pertenecen a 20 categorías diferentes.\n",
    "\n",
    "El objetivo es entender los conceptos que se trabajan y ser capaz de hacer pequeñas experimentaciones para mejorar el Notebook creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1686419217737,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "Ytpb1W-imjkg"
   },
   "outputs": [],
   "source": [
    "#Basado en:\n",
    "#https://keras.io/examples/nlp/pretrained_word_embeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hytURWLLjZvT"
   },
   "source": [
    "#Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8993,
     "status": "ok",
     "timestamp": 1686419226961,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "DbxRuvOwkzSs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXfYbCflkQYy"
   },
   "source": [
    "# Descarga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6354,
     "status": "ok",
     "timestamp": 1686419233308,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "e-1ZhOf3lB_A"
   },
   "outputs": [],
   "source": [
    "data_path = keras.utils.get_file(\n",
    "    \"news20.tar.gz\",\n",
    "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
    "    untar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1686419233309,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "l3ygvoWhlCYj",
    "outputId": "71e576a4-853b-45a2-9617-a1ad7df0e4d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of directories: 20\n",
      "Directory names: ['rec.sport.hockey', 'soc.religion.christian', 'sci.space', 'rec.autos', 'comp.graphics', 'talk.politics.misc', 'comp.windows.x', 'misc.forsale', 'sci.crypt', 'talk.politics.guns', 'alt.atheism', 'talk.religion.misc', 'comp.os.ms-windows.misc', 'comp.sys.mac.hardware', 'talk.politics.mideast', 'comp.sys.ibm.pc.hardware', 'sci.med', 'rec.sport.baseball', 'sci.electronics', 'rec.motorcycles']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "#Estructura de directorios del dataset\n",
    "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
    "dirnames = os.listdir(data_dir)\n",
    "print(\"Number of directories:\", len(dirnames))\n",
    "print(\"Directory names:\", dirnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1686419233311,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "OG8rjgOFlcaV",
    "outputId": "6ab308e9-09d5-4cc9-934c-2a0d5ce8e219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in comp.graphics: 1000\n",
      "Some example filenames: ['38399', '39659', '38452', '38752', '38635']\n"
     ]
    }
   ],
   "source": [
    "#Algunos archivos de la categoria \"com.graphics\"\n",
    "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
    "print(\"Number of files in comp.graphics:\", len(fnames))\n",
    "print(\"Some example filenames:\", fnames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1686419233313,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "8ox6s6z9lgps",
    "outputId": "00ce9751-cd20-4c4e-ffda-6ff2bff99c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: cantaloupe.srv.cs.cmu.edu!rochester!udel!gatech!howland.reston.ans.net!newsserver.jvnc.net!castor.hahnemann.edu!hal.hahnemann.edu!brennan\n",
      "From: brennan@hal.hahnemann.edu\n",
      "Newsgroups: comp.graphics\n",
      "Subject: .GIFs on a Tek401x ??\n",
      "Date: 15 MAY 93 14:29:54 EST\n",
      "Organization: Hahnemann University\n",
      "Lines: 14\n",
      "Message-ID: <15MAY93.14295461@hal.hahnemann.edu>\n",
      "NNTP-Posting-Host: hal.hahnemann.edu\n",
      "\n",
      "\n",
      "      I was skimming through a few gophers and bumped into one at NIH\n",
      "   with a database that included images in .GIF format.  While I have\n",
      "   not yet worked out the kinks of getting the gopher client to call\n",
      "   an X viewer, I figure that the majority of the users here are not\n",
      "   in an X11 environment - instead using DOS and MS-Kermit.\n",
      "\n",
      "      With Kermit supporting Tek4010 emulation for graphics display,\n",
      "   does anyone know of a package that would allow a Tek to display a\n",
      "   .GIF image?  It would be of more use to the local population to\n",
      "   plug something of this sort in as the 'picture' command instead of\n",
      "   XView or XLoadImage ...\n",
      "\n",
      "      andrew.  (brennan@hal.hahnemann.edu)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo de un texto de la categoría \"com.graphics\"\n",
    "print(open(data_dir / \"comp.graphics\" / \"39625\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tx3-RRHZik6N"
   },
   "source": [
    "<font color='green'>**Pregunta 1 (0.5 puntos): Escribe un texto de la categoría 'sci.electronics'**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1686419233314,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "mFQ3AuODij9h",
    "outputId": "5f970245-68d8-45aa-ed69-3e442fecc893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in sci.electronics: 1000\n",
      "\n",
      "Some example filenames: ['53804', '53962', '53937', '54051', '53685']\n",
      "\n",
      "Select random filename in sci.electronics...\n",
      "\n",
      "A random example of sci.electronics:\n",
      "\n",
      "Newsgroups: sci.electronics\n",
      "Path: cantaloupe.srv.cs.cmu.edu!rochester!udel!bogus.sura.net!darwin.sura.net!zaphod.mps.ohio-state.edu!magnus.acs.ohio-state.edu!mbattist\n",
      "From: mbattist@magnus.acs.ohio-state.edu (Mark A Battisti)\n",
      "Subject: Re: Clear LCD or LED \"sheets\"\n",
      "Message-ID: <1993Apr26.183654.29750@magnus.acs.ohio-state.edu>\n",
      "Sender: news@magnus.acs.ohio-state.edu\n",
      "Nntp-Posting-Host: magnusug.magnus.acs.ohio-state.edu\n",
      "Organization: The Ohio State University\n",
      " writes:\n",
      "References: <1993Apr26.141409.22154@magnus.acs.ohio-state.edu> <1rgssrINNnqb@ga\n",
      "Distribution: usa\n",
      "Date: Mon, 26 Apr 1993 18:36:54 GMT\n",
      "Lines: 13\n",
      "\n",
      ">>An ideal item would be an LED array for which each LED is about 1/2\" square.\n",
      ">>(Yes very coarse)  This is for distance viewing, but on a window.\n",
      ">>Any pointers of suggestions would be much appreciated.\n",
      ">\n",
      ">What, pray tell, are you putting together?  And what about costs?  And does it\n",
      ">have to be transparent as in totally transparent?  Or just transparent enough\n",
      ">to allow light from the other side to shine through?\n",
      "\n",
      "Yes it has to be very clear (like it wasn't there).  And of course, cost is \n",
      "always a factor.  I am trying to get an idea of the feasability of such an \n",
      "idea.  But I don't want to give too much away.\n",
      "\n",
      "-Mark\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tu respuesta aqui\n",
    "# seleccionando los filenames de 'sci.electronics':\n",
    "fnames_sci = os.listdir(data_dir / \"sci.electronics\")\n",
    "print(\"Number of files in sci.electronics: {}\\n\".format(len(fnames_sci)))\n",
    "print(\"Some example filenames: {}\\n\".format(fnames_sci[:5]))\n",
    "print(\"Select random filename in sci.electronics...\\n\")\n",
    "rndm_filename = np.random.choice(fnames_sci)\n",
    "print(\"A random example of sci.electronics:\\n\")\n",
    "print(open(data_dir / \"sci.electronics\" / rndm_filename).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1073,
     "status": "ok",
     "timestamp": 1686419234362,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "33Ay5U6blCd1",
    "outputId": "371f30a0-1fb9-4ab3-d736-ddbc5a7743b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alt.atheism, 1000 files found\n",
      "Processing comp.graphics, 1000 files found\n",
      "Processing comp.os.ms-windows.misc, 1000 files found\n",
      "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
      "Processing comp.sys.mac.hardware, 1000 files found\n",
      "Processing comp.windows.x, 1000 files found\n",
      "Processing misc.forsale, 1000 files found\n",
      "Processing rec.autos, 1000 files found\n",
      "Processing rec.motorcycles, 1000 files found\n",
      "Processing rec.sport.baseball, 1000 files found\n",
      "Processing rec.sport.hockey, 1000 files found\n",
      "Processing sci.crypt, 1000 files found\n",
      "Processing sci.electronics, 1000 files found\n",
      "Processing sci.med, 1000 files found\n",
      "Processing sci.space, 1000 files found\n",
      "Processing soc.religion.christian, 997 files found\n",
      "Processing talk.politics.guns, 1000 files found\n",
      "Processing talk.politics.mideast, 1000 files found\n",
      "Processing talk.politics.misc, 1000 files found\n",
      "Processing talk.religion.misc, 1000 files found\n",
      "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of samples: 19997\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "class_names = []\n",
    "class_index = 0\n",
    "for dirname in sorted(os.listdir(data_dir)):\n",
    "    class_names.append(dirname)\n",
    "    dirpath = data_dir / dirname\n",
    "    fnames = os.listdir(dirpath)\n",
    "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
    "    for fname in fnames:\n",
    "        fpath = dirpath / fname\n",
    "        f = open(fpath, encoding=\"latin-1\")\n",
    "        content = f.read()\n",
    "        lines = content.split(\"\\n\")\n",
    "        lines = lines[10:]\n",
    "        content = \"\\n\".join(lines)\n",
    "        samples.append(content)\n",
    "        labels.append(class_index)\n",
    "    class_index += 1\n",
    "\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Number of samples:\", len(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2pmvE6gMcxT"
   },
   "source": [
    "# Mezclando los datos para separarlos en Traning y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1686419234365,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "DYX7x-k_lCgZ"
   },
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "seed = 1337\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(samples)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "# Extract a training & validation split\n",
    "validation_split = 0.2\n",
    "num_validation_samples = int(validation_split * len(samples))\n",
    "train_samples = samples[:-num_validation_samples]\n",
    "val_samples = samples[-num_validation_samples:]\n",
    "train_labels = labels[:-num_validation_samples]\n",
    "val_labels = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMrE0T4wMj09"
   },
   "source": [
    "<font color='green'>**Pregunta 2 (0.5 puntos): ¿Por qué mezclamos los datos antes de separarlos en entrenamiento y validación?**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mMlhaI3BDZX"
   },
   "source": [
    "**Tu respuesta aqui:**\n",
    "Para evitar el sobreajuste (overfitting) de una determinada porción de categorías. Así, al mezclar los datos nos aseguramos que todas las categorías se encuentren representadas en el conjunto de datos de training, de esa manera evitamos el sesgo del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCPGWsdDjlIS"
   },
   "source": [
    "<font color='green'>**Pregunta 3 (1 punto): ¿Por qué estás seguro que en la división aleatoria cada muestra coincide con su etiqueta correcta?**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1L7BoeCHBUaZ"
   },
   "source": [
    "**Tu respuesta aqui:** Porque al utilizar la misma semilla (1337) estamos asegurandonos que la mezcla aleatoria siga la misma permutación de los datos, por tanto los valores de samples y labels se permutan en el mismo orden en las listas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IktOtKfpNx8E"
   },
   "source": [
    "# Tokenización de las palabras con TextVectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5158,
     "status": "ok",
     "timestamp": 1686419239512,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "QjHgQPX8lCjO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1686419239515,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "vIWC37s5smZ4",
    "outputId": "368f8556-ca03-41e1-e7fd-fc05d3903474"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'to', 'of']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1686419239515,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "vit8TPqTvmwS",
    "outputId": "cd18dac0-0d7f-48ac-b3ac-f8849c09195c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yttb9K8vssAz"
   },
   "source": [
    "<font color='green'>**Pregunta 4 (2 puntos): En la construcción del vocabulario hemos limitado el número de tokens a 20.000 ¿Podrías indicar el número de token diferentes o tamaño del vocabulario sin limitar el número de tokens? Es decir, ¿Cuántas palabras diferentes existen en los documentos procesados como instancias?**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3295,
     "status": "ok",
     "timestamp": 1686419242795,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "SZIgywwYquDE",
    "outputId": "e7490195-2ef4-4285-f944-0fc689de5e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary has 162113 tokens\n",
      "\n",
      "There are no repeated elements\n"
     ]
    }
   ],
   "source": [
    "#Tu código para responder a esta pregunta aqui:\n",
    "# Procedemos a crear un vectorizer 'without_limit' sin limitar el vocabulario\n",
    "# luego adaptamos el texto de train_samples:\n",
    "without_limit = TextVectorization(max_tokens=None, output_sequence_length=None)\n",
    "text_ds_2 = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "# vectorizando el text_ds_2:\n",
    "without_limit.adapt(text_ds_2)\n",
    "# longitud del vocabulario en tokens:\n",
    "print(\"The vocabulary has {} tokens\\n\".format(len(without_limit.get_vocabulary())))\n",
    "voc_lst = without_limit.get_vocabulary()\n",
    "\n",
    "# Definimos una función para verificar que no existen tokens repetidos: \n",
    "def repeated_elements(voc_lst):\n",
    "    conjunto = set(voc_lst)\n",
    "    if len(conjunto) < len(voc_lst):\n",
    "        print(\"There are repeated elements\")\n",
    "    else:\n",
    "        print(\"There are no repeated elements\")\n",
    "\n",
    "repeated_elements(voc_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2O-FXA9wPVkg"
   },
   "source": [
    "# Viendo la salida de Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1686419242796,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "rseIF0fLmyJ0",
    "outputId": "98df9612-7754-4dc8-de90-3d0f9ce6fe6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2, 3451, 1697,   15,    2, 6678])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"the cat sat on the mat\"]])\n",
    "output.numpy()[0, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1686419242797,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "Wsr4AQtBFArV",
    "outputId": "f2d242ef-b053-444b-9990-26e967f67254"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 200), dtype=int64, numpy=\n",
       "array([[   2, 3451, 1697,   15,    2, 6678,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1686419243032,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "SL5ag8UamzwL"
   },
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1686419243033,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "08v8SKcsn3lf",
    "outputId": "a2f7b9fe-15ab-4904-b786-28814bf215a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3451, 1697, 15, 2, 6678]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "[word_index[w] for w in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWxZ5Z0sF_d8"
   },
   "source": [
    "<font color='green'>**Pregunta 5 (1 punto): Arriba tenemos la codificación de la frase \"the cat sat on the mat\". Imagina la siguiente situación. La salida de vectorizer() para codificar los tokens [\"El\", \"gato\", \"está\", \"sobre\", \"el\", \"tejado\"] es la siguiente [1, 121, 405, 1, 45, 4561]. Si cada uno de los valores indica el índice en el que se encuentra cada palabra en el array creado para codificarla. ¿Podría ser correcta esta salida?**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzpDT-W9GN4o"
   },
   "source": [
    "**Tu respuesta aqui:** La codificación mostrada es incorrecta, debido a que el vocabulario proviene de una tokenización, entonces las palabras \"El\" y \"el\" deberían tener la misma codificación y no la tienen, \"El\" es 1 y \"el\" es 45. También, teniendo en cuenta la codificación de \"El\" que es 1, en la cuarta posición está \"sobre\" que se codifica igual como 1, lo cual no es correcto y no tiene sentido tampoco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eBhadrvOTNZ"
   },
   "source": [
    "# Tokenización de los datos de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 10672,
     "status": "ok",
     "timestamp": 1686419253696,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "W26LUr2dKTOj"
   },
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGvYD56WlhaA"
   },
   "source": [
    "# Creación del modelo con un embedding hecho a mano y con redes neuronales convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI0TYBbvHNwr"
   },
   "source": [
    "Aunque las Redes Neuronales Convolucionales se desarrollaron originalmente para procesamiento de imágenes, se pueden aplicar a problemas de procesamiento de lenguaje natural gracias a su capacidad para capturar patrones locales y globales en los datos de entrada.\n",
    "\n",
    "Previa a la alimentación de las capas convolucionales, vamos a incluir una capa de Embedding. Como hemos visto en clase, un embedding de palabras se refiere a una representación vectorial densa de una palabra en un espacio de características continuo de alta dimensión. Como resultado del embedding vamos capturar la semántica de las palabras de manera que palabras similares tengan representaciones vectoriales similares.\n",
    "\n",
    "A continuación se incluye la creación de un modelo con un embedding hecho a mano y usando  Redes Neuronales Convolucionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1686419253970,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "AT8KYdHaOh31"
   },
   "outputs": [],
   "source": [
    "modeloEmbeddingManualConvolucionales = keras.models.Sequential()\n",
    "modeloEmbeddingManualConvolucionales.add(keras.layers.Embedding(20000, 10, input_length=200))\n",
    "modeloEmbeddingManualConvolucionales.add(keras.layers.Conv1D(128, 5, activation=\"relu\"))\n",
    "modeloEmbeddingManualConvolucionales.add(keras.layers.MaxPooling1D(5))\n",
    "modeloEmbeddingManualConvolucionales.add(keras.layers.Conv1D(128, 5, activation=\"relu\"))\n",
    "modeloEmbeddingManualConvolucionales.add(keras.layers.MaxPooling1D(5))\n",
    "modeloEmbeddingManualConvolucionales.add(keras.layers.Conv1D(128, 5, activation=\"relu\"))\n",
    "modeloEmbeddingManualConvolucionales.add(keras.layers.GlobalMaxPooling1D())\n",
    "modeloEmbeddingManualConvolucionales.add(keras.layers.Dense(128, activation='relu'))\n",
    "modeloEmbeddingManualConvolucionales.add(keras.layers.Dropout(0.3))\n",
    "modeloEmbeddingManualConvolucionales.add(keras.layers.Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142866,
     "status": "ok",
     "timestamp": 1686419396825,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "xtx8L9hJm-lQ",
    "outputId": "db6f4d3b-d077-4961-9a28-31f908e67616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 30s 156ms/step - loss: 2.9285 - acc: 0.0698 - val_loss: 2.6645 - val_acc: 0.1085\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 2.5296 - acc: 0.1228 - val_loss: 2.4305 - val_acc: 0.1413\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 11s 85ms/step - loss: 2.2943 - acc: 0.1612 - val_loss: 2.1812 - val_acc: 0.2063\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 2.1216 - acc: 0.1999 - val_loss: 2.0665 - val_acc: 0.2268\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 1.9475 - acc: 0.2474 - val_loss: 1.9142 - val_acc: 0.2928\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 8s 61ms/step - loss: 1.7646 - acc: 0.3144 - val_loss: 1.8447 - val_acc: 0.3071\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 4s 29ms/step - loss: 1.5633 - acc: 0.3852 - val_loss: 1.6393 - val_acc: 0.4184\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 4s 34ms/step - loss: 1.3876 - acc: 0.4702 - val_loss: 1.5856 - val_acc: 0.4586\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 4s 34ms/step - loss: 1.2437 - acc: 0.5331 - val_loss: 1.5517 - val_acc: 0.4699\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 1.0991 - acc: 0.5949 - val_loss: 1.5114 - val_acc: 0.5276\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.9822 - acc: 0.6437 - val_loss: 1.6663 - val_acc: 0.4751\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.9060 - acc: 0.6784 - val_loss: 1.4618 - val_acc: 0.5734\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.8151 - acc: 0.7147 - val_loss: 1.6786 - val_acc: 0.5339\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.7370 - acc: 0.7433 - val_loss: 1.5624 - val_acc: 0.5714\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.6889 - acc: 0.7682 - val_loss: 1.5937 - val_acc: 0.5674\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 0.6443 - acc: 0.7812 - val_loss: 1.8221 - val_acc: 0.5554\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.5959 - acc: 0.7962 - val_loss: 1.9092 - val_acc: 0.5409\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.5285 - acc: 0.8189 - val_loss: 2.2952 - val_acc: 0.5229\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.5065 - acc: 0.8320 - val_loss: 1.8511 - val_acc: 0.5739\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.4714 - acc: 0.8412 - val_loss: 1.7246 - val_acc: 0.6134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9fd0f713f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloEmbeddingManualConvolucionales.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "modeloEmbeddingManualConvolucionales.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "modeloEmbeddingManualConvolucionales.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KW8w16t_IrHY"
   },
   "source": [
    "<font color='green'>**Pregunta 6 (1 punto): ¿Por qué usamos convoluciones de 1 dimensión para procesar texto?**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6taJP56qJCuH"
   },
   "source": [
    "**Tu respuesta aqui:** A diferencia de los modelos de redes neuronales convolucionales para imagenes en los que se usa Conv2D, debido a que las imágenes son de dos dimensiones y los datos de textos están en una sola dimensión, conocidos como sequencias de caracteres, por tal razón se usan redes convolucionales en 1D. Las redes convolucionales en 1D también se pueden usar en series de tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3QVIb84Olda"
   },
   "source": [
    "#Creación del modelo con un embedding hecho a mano con redes neuronales clásicas\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3olUvuUVLc4U"
   },
   "source": [
    "<font color='green'>**Pregunta 7 (2 puntos): Crea un nuevo modelo partiendo del model anterior pero en lugar de Redes Neuronales Convolucionales vamos a utilizar Redes Neuronales Clásicas. Para ello, tras la capa Embedding añade una capa Flatten, una capa densa de 512 neuronas con función de activación relu y una capa Dropout de regulización al 30%. Por último, no olvides incluir la capa de salida con tantas neuronas como clases haya y la función de activación softmax.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fS6KGaR_SFEv"
   },
   "source": [
    "**Tu respuesta aqui:** Se crea un modelo secuencial, con la primera capa Embedding con tamaño de vocavulario 20000, tamaño de vector de embedding 10 y longitud de las secuencias de entrada 200. posteriormente, una capa densa de 512 nueronas con función de activación ReLU y una capa dropout de 30%. Finalmente la capad de salida para entregar el vector de probabilidades de las 20 categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1686419396826,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "VTDrdvQyOlda"
   },
   "outputs": [],
   "source": [
    "# Tu código aqui:\n",
    "modeloEmbeddingManualClasicas = keras.models.Sequential()\n",
    "modeloEmbeddingManualClasicas.add(keras.layers.Embedding(20000, 10, input_length=200))\n",
    "modeloEmbeddingManualClasicas.add(keras.layers.Flatten())\n",
    "modeloEmbeddingManualClasicas.add(keras.layers.Dense(512, activation='relu'))\n",
    "modeloEmbeddingManualClasicas.add(keras.layers.Dropout(0.3))\n",
    "modeloEmbeddingManualClasicas.add(keras.layers.Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74627,
     "status": "ok",
     "timestamp": 1686419471443,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "qD_hqn2sOlda",
    "outputId": "c42f7322-974f-4367-c91d-3aff2cad0ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 14s 106ms/step - loss: 2.8812 - acc: 0.1044 - val_loss: 2.6420 - val_acc: 0.1615\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 9s 76ms/step - loss: 2.2863 - acc: 0.2590 - val_loss: 2.0703 - val_acc: 0.3003\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 8s 61ms/step - loss: 1.6822 - acc: 0.4592 - val_loss: 1.6473 - val_acc: 0.4281\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 7s 53ms/step - loss: 1.1654 - acc: 0.6478 - val_loss: 1.3265 - val_acc: 0.5641\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 5s 40ms/step - loss: 0.7902 - acc: 0.7732 - val_loss: 1.1442 - val_acc: 0.6164\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.5500 - acc: 0.8421 - val_loss: 1.0643 - val_acc: 0.6374\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 4s 36ms/step - loss: 0.3913 - acc: 0.8916 - val_loss: 1.0377 - val_acc: 0.6574\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.2950 - acc: 0.9155 - val_loss: 1.0329 - val_acc: 0.6727\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.2279 - acc: 0.9353 - val_loss: 1.0530 - val_acc: 0.6804\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.1872 - acc: 0.9439 - val_loss: 1.0880 - val_acc: 0.6759\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.1604 - acc: 0.9490 - val_loss: 1.1196 - val_acc: 0.6834\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 0.1391 - acc: 0.9551 - val_loss: 1.1163 - val_acc: 0.6847\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.1270 - acc: 0.9574 - val_loss: 1.1542 - val_acc: 0.6789\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.1168 - acc: 0.9600 - val_loss: 1.1807 - val_acc: 0.6852\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.1095 - acc: 0.9606 - val_loss: 1.1959 - val_acc: 0.6874\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1027 - acc: 0.9625 - val_loss: 1.1955 - val_acc: 0.6899\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0978 - acc: 0.9619 - val_loss: 1.2160 - val_acc: 0.6899\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.0921 - acc: 0.9652 - val_loss: 1.2535 - val_acc: 0.6842\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.0929 - acc: 0.9639 - val_loss: 1.2376 - val_acc: 0.6872\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 0.0864 - acc: 0.9654 - val_loss: 1.2345 - val_acc: 0.6927\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 200, 10)           200000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2000)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1024512   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                10260     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,234,772\n",
      "Trainable params: 1,234,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "modeloEmbeddingManualClasicas.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "modeloEmbeddingManualClasicas.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "modeloEmbeddingManualClasicas.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))\n",
    "print(modeloEmbeddingManualClasicas.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27PnPdfGMgQA"
   },
   "source": [
    "Tras hacer este experimento, es posible que pase una cosa curiosa y es que la red totalmente conectada tenga un mejor comportamiento que la convolucional. \n",
    "En general, las redes neuronales convolucionales tienden a superar a las totalmente conectadas en la mayoría de los problemas de este tipo debido a su capacidad para capturar patrones espaciales y posicionales en los datos de entrada. Dicho esto, en algunos casos, una red neuronal clásica podría superar a una convolucional en un problema de procesamiento de lenguaje natural, especialmente si el conjunto de datos es pequeño y las características relevantes son relativamente simples. En este caso, la mayoría de las categorías puede ser que tengan un vocabulario específico y esa pueda ser una de las razones. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZL7wt0r_9Os"
   },
   "source": [
    "#Creación del modelo con el embedding GloVe y redes neuronales convolucionales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAvOGIybNH-C"
   },
   "source": [
    "Esta vez, en vez de crear nosotros mismos el embedding, vamos a utilizar Glove. Los vectores de palabras generados por GloVe capturan las relaciones semánticas y sintácticas entre las palabras en un corpus de texto mucho más grande que el nuestro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298487,
     "status": "ok",
     "timestamp": 1686419769895,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "xkzAfY0v72EM",
    "outputId": "0ef2d3f0-8395-4e2e-ddd4-9ba6422e57d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-10 17:51:11--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2023-06-10 17:51:11--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2023-06-10 17:51:11--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip.1’\n",
      "\n",
      "glove.6B.zip.1      100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
      "\n",
      "2023-06-10 17:53:50 (5.18 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
      "\n",
      "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace glove.6B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOf0LXFuOJBG"
   },
   "source": [
    "<font color='green'>**Pregunta 8 (1 puntos): \tEl embedding que usa la actividad es el glove.6B. ¿De dónde se han obtenido los textos que se han usado para entrenarlo? ¿Cántos WordVectors lo componen? ¿De cuántas dimensiones tiene versiones? Puedes ayudarte del link https://nlp.stanford.edu/projects/glove/ para buscar la información**</font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DkrpVKuOt3-"
   },
   "source": [
    "**Tu respuesta aqui:** Los textos utilizados para GloVe.6B son los siguientes:<br>\n",
    "* Wikipedia 2014 en diferentes idiomas.\n",
    "* Gigaword 5: está compuesto por artículos de noticias y textos de diferentes fuentes y dominios, recopilados a lo largo de varios años hasta dicimebre de 2010. Está compuesto de 6B tokens y de 400k word vectors (vocabulario). Cuenta con versiones de 50d, 100d, 200d, & 300d vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6708,
     "status": "ok",
     "timestamp": 1686419776578,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "m-bSZXrqoAEg",
    "outputId": "0a9146c9-7c92-447d-f465-5d57145dba82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = os.path.join(\n",
    "    os.path.expanduser(\"~\"), \".keras/datasets/glove.6B.100d.txt\"\n",
    ")\n",
    "path_to_glove_file = \"glove.6B.100d.txt\"\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdKbdVax2e_l"
   },
   "source": [
    "Creamos la capa Embedding de keras. Se trata de una matrix numpy donde el valor de cada posición corresponde con el vector pre-entreneado del vocabulario tras el vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1686419776580,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "R2Tov2B6oBuF",
    "outputId": "a31e1360-e108-43cd-c2aa-d4c8fa58c882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 17954 words (2046 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akWSH27b21AY"
   },
   "source": [
    "Cargamos el embedding como una capa keras. Al poner trainable=False nos quedamos con los valores del modelo pre-entrenado, es decir, no actualizamos estos valores a lo largo del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1686419776581,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "w40nHAAPoD0J"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1686419776861,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "UoPboJ6l_9Ot",
    "outputId": "ae14fa27-fbc2-4ae8-9ba4-038f1f171678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, None, 100)         2000200   \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, None, 128)         64128     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, None, 128)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, None, 128)         82048     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, None, 128)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, None, 128)         82048     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,247,516\n",
      "Trainable params: 247,316\n",
      "Non-trainable params: 2,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "modelEmbeddingGloveConvolucionales = keras.Model(int_sequences_input, preds)\n",
    "modelEmbeddingGloveConvolucionales.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42430,
     "status": "ok",
     "timestamp": 1686419819282,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "nllcCJY__9Ot",
    "outputId": "69cf957a-4b29-43b9-9ed3-9df979afbb27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 3s 13ms/step - loss: 2.7018 - acc: 0.1264 - val_loss: 2.2242 - val_acc: 0.2343\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 2.0104 - acc: 0.3101 - val_loss: 1.6258 - val_acc: 0.4424\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 1.5472 - acc: 0.4697 - val_loss: 1.2912 - val_acc: 0.5596\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 1.2982 - acc: 0.5562 - val_loss: 1.2218 - val_acc: 0.5724\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 1.1288 - acc: 0.6107 - val_loss: 1.1361 - val_acc: 0.6122\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.9959 - acc: 0.6614 - val_loss: 1.0279 - val_acc: 0.6457\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.8874 - acc: 0.6908 - val_loss: 1.0778 - val_acc: 0.6379\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.7736 - acc: 0.7311 - val_loss: 0.9893 - val_acc: 0.6692\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.6839 - acc: 0.7592 - val_loss: 1.0183 - val_acc: 0.6702\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.6128 - acc: 0.7832 - val_loss: 1.1213 - val_acc: 0.6639\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.5346 - acc: 0.8102 - val_loss: 1.0735 - val_acc: 0.6847\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.4747 - acc: 0.8324 - val_loss: 1.2298 - val_acc: 0.6547\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.4096 - acc: 0.8559 - val_loss: 1.1926 - val_acc: 0.6842\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.3706 - acc: 0.8699 - val_loss: 1.4700 - val_acc: 0.6489\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.3272 - acc: 0.8862 - val_loss: 1.2639 - val_acc: 0.6852\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2835 - acc: 0.9008 - val_loss: 1.1197 - val_acc: 0.7207\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2712 - acc: 0.9081 - val_loss: 1.4198 - val_acc: 0.6762\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2411 - acc: 0.9193 - val_loss: 1.4628 - val_acc: 0.6904\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2177 - acc: 0.9272 - val_loss: 1.5059 - val_acc: 0.6789\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2077 - acc: 0.9294 - val_loss: 1.3287 - val_acc: 0.7059\n",
      "125/125 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "modelEmbeddingGloveConvolucionales.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "modelEmbeddingGloveConvolucionales.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))\n",
    "predictions = modelEmbeddingGloveConvolucionales.predict(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YySP5H70BQcx"
   },
   "source": [
    "#Creación del modelo final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oo0aRSmoOz6s"
   },
   "source": [
    "<font color='green'>**Pregunta 9 (1 puntos): \tA estas alturas ya te habrás dado cuenta que los Transformer que has utilizado en la asignatura de Procesamiento de Lenguaje Natural son, probablemente, los que mejores resultados obtienen. Sin utilizar Transformer, crea un modelo tú, bien ajustando los hiperparámetros de los modelos anteriores o uno completamente nuevo, que llegue al menos al 72% accuracy**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGRWtKtHRYpJ"
   },
   "source": [
    "**Tu respuesta aqui:** Es este caso, se utliza el modelo anteriormente planteado pero adicionando una capa LSTM con 256 parámetros de entrada después de la capa de Embedding. Esto, permite al modelo aprender y utilizar patrones más complejos en la secuencia de entrada, capturando dependencias temporales a largo plazo. También, se modificaron la cantidad de parametros a las dos primeras capas convolucionales de 128 a 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 678,
     "status": "ok",
     "timestamp": 1686421176284,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "Dyy9CPpCGmbL",
    "outputId": "8f4ec8e6-27b7-4a93-ee5b-cd7fd229ca0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, None, 100)         2000200   \n",
      "                                                                 \n",
      " conv1d_34 (Conv1D)          (None, None, 256)         128256    \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPoolin  (None, None, 256)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, None, 256)         327936    \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPoolin  (None, None, 256)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_36 (Conv1D)          (None, None, 128)         163968    \n",
      "                                                                 \n",
      " global_max_pooling1d_9 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 256)               394240    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,050,076\n",
      "Trainable params: 1,049,876\n",
      "Non-trainable params: 2,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Tu codigo aqui:\n",
    "# Se importa LSTM:\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "int_sequences_input_2 = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences1 = embedding_layer(int_sequences_input_2)\n",
    "x1 = layers.Conv1D(256, 5, activation=\"relu\")(embedded_sequences1)\n",
    "x1 = layers.MaxPooling1D(5)(x1)\n",
    "x1 = layers.Conv1D(256, 5, activation=\"relu\")(x1)\n",
    "x1 = layers.MaxPooling1D(5)(x1)\n",
    "x1 = layers.Conv1D(128, 5, activation=\"relu\")(x1)\n",
    "x1 = layers.GlobalMaxPooling1D()(x1)\n",
    "# Se añade la capa LSTM con capacidad para procesar información con 256 estados:\n",
    "x1 = layers.Reshape((-1, 128))(x1)\n",
    "x1 = LSTM(256)(x1)\n",
    "x1 = layers.Dense(128, activation=\"relu\")(x1)\n",
    "x1 = layers.Dropout(0.5)(x1)\n",
    "preds1 = layers.Dense(len(class_names), activation=\"softmax\")(x1)\n",
    "modelEmbeddingGloveConvolucionales1 = keras.Model(int_sequences_input_2, preds1)\n",
    "modelEmbeddingGloveConvolucionales1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85170,
     "status": "ok",
     "timestamp": 1686421265928,
     "user": {
      "displayName": "Ruben Dario Aponte Nuñez (rubenapu)",
      "userId": "12152701990531547488"
     },
     "user_tz": 300
    },
    "id": "GLGPwsUR7Niu",
    "outputId": "30d4353f-1eda-4272-e464-99c6f980c6f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 6s 28ms/step - loss: 2.7395 - acc: 0.1041 - val_loss: 2.4089 - val_acc: 0.1753\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.1300 - acc: 0.2430 - val_loss: 1.8666 - val_acc: 0.3361\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.7249 - acc: 0.3807 - val_loss: 1.4225 - val_acc: 0.4884\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.4263 - acc: 0.4860 - val_loss: 1.2697 - val_acc: 0.5451\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.2133 - acc: 0.5672 - val_loss: 1.1301 - val_acc: 0.5984\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0490 - acc: 0.6320 - val_loss: 1.0460 - val_acc: 0.6387\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.9075 - acc: 0.6790 - val_loss: 1.0548 - val_acc: 0.6469\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.7785 - acc: 0.7198 - val_loss: 1.0974 - val_acc: 0.6484\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.6817 - acc: 0.7522 - val_loss: 1.0224 - val_acc: 0.6697\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.5845 - acc: 0.7813 - val_loss: 1.2584 - val_acc: 0.6402\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.5215 - acc: 0.8078 - val_loss: 1.0564 - val_acc: 0.6912\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4430 - acc: 0.8372 - val_loss: 1.0972 - val_acc: 0.7067\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.3936 - acc: 0.8563 - val_loss: 1.0517 - val_acc: 0.7204\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.3381 - acc: 0.8789 - val_loss: 1.2152 - val_acc: 0.6934\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.2993 - acc: 0.8963 - val_loss: 1.1026 - val_acc: 0.7274\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2665 - acc: 0.9080 - val_loss: 1.1828 - val_acc: 0.7302\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.2205 - acc: 0.9262 - val_loss: 1.2921 - val_acc: 0.7094\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.2074 - acc: 0.9327 - val_loss: 1.2534 - val_acc: 0.7304\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.1894 - acc: 0.9352 - val_loss: 1.4275 - val_acc: 0.7269\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.1684 - acc: 0.9417 - val_loss: 1.3859 - val_acc: 0.7277\n",
      "125/125 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "modelEmbeddingGloveConvolucionales1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "modelEmbeddingGloveConvolucionales1.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))\n",
    "predictions1 = modelEmbeddingGloveConvolucionales1.predict(x_val)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
